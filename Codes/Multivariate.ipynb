{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2015-02-04 17:51:00\n",
       "1       2015-02-04 17:51:59\n",
       "2       2015-02-04 17:53:00\n",
       "3       2015-02-04 17:54:00\n",
       "4       2015-02-04 17:55:00\n",
       "                ...        \n",
       "17890   2015-02-18 09:15:00\n",
       "17891   2015-02-18 09:16:00\n",
       "17892   2015-02-18 09:16:59\n",
       "17893   2015-02-18 09:17:59\n",
       "17894   2015-02-18 09:19:00\n",
       "Name: date, Length: 17895, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('D://Documenti//Università//Informatica Umanistica//DMII//occupancy_data//datatraining.txt', skipinitialspace=True, na_values='?', \n",
    "                 keep_default_na=True)\n",
    "df2 = pd.read_csv('D://Documenti//Università//Informatica Umanistica//DMII//occupancy_data//datatest2.txt', skipinitialspace=True, na_values='?', \n",
    "                 keep_default_na=True,)\n",
    "\n",
    "df = pd.concat([df1,df2], ignore_index = True)\n",
    "pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(df['date'], infer_datetime_format=True)\n",
    "df['day'] = dates.dt.day\n",
    "df['absH'] = dates.dt.hour\n",
    "\n",
    "del df['HumidityRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>day</th>\n",
       "      <th>absH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-04 17:51:00</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-04 17:51:59</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-04 17:53:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-04 17:54:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-04 17:55:00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Temperature  Humidity  Light     CO2  Occupancy  day  \\\n",
       "0  2015-02-04 17:51:00        23.18   27.2720  426.0  721.25          1    4   \n",
       "1  2015-02-04 17:51:59        23.15   27.2675  429.5  714.00          1    4   \n",
       "2  2015-02-04 17:53:00        23.15   27.2450  426.0  713.50          1    4   \n",
       "3  2015-02-04 17:54:00        23.15   27.2000  426.0  708.25          1    4   \n",
       "4  2015-02-04 17:55:00        23.10   27.2000  426.0  704.50          1    4   \n",
       "\n",
       "   absH  \n",
       "0    17  \n",
       "1    17  \n",
       "2    17  \n",
       "3    17  \n",
       "4    17  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un dataset contenente solo i valori del giorno 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.day==9]\n",
    "del df['day']\n",
    "del df['Occupancy']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo TS per ora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[df.absH==0]\n",
    "df0 = df0.set_index('date')\n",
    "del df0['absH']\n",
    "df0 = df0[:59]\n",
    "df0 = df0.transpose()\n",
    "\n",
    "df1 = df[df.absH==1]\n",
    "df1 = df1.set_index('date')\n",
    "del df1['absH']\n",
    "df1 = df1[:59]\n",
    "df1 = df1.transpose()\n",
    "\n",
    "df2 = df[df.absH==2]\n",
    "df2 = df2.set_index('date')\n",
    "del df2['absH']\n",
    "df2 = df2[:59]\n",
    "df2 = df2.transpose()\n",
    "\n",
    "df3 = df[df.absH==3]\n",
    "df3 = df3.set_index('date')\n",
    "del df3['absH']\n",
    "df3 = df3[:59]\n",
    "df3 = df3.transpose()\n",
    "\n",
    "df4 = df[df.absH==4]\n",
    "df4 = df4.set_index('date')\n",
    "del df4['absH']\n",
    "df4 = df4[:59]\n",
    "df4 = df4.transpose()\n",
    "\n",
    "df5 = df[df.absH==5]\n",
    "df5 = df5.set_index('date')\n",
    "del df5['absH']\n",
    "df5 = df5[:59]\n",
    "df5 = df5.transpose()\n",
    "\n",
    "df6 = df[df.absH==6]\n",
    "df6 = df6.set_index('date')\n",
    "del df6['absH']\n",
    "df6 = df6[:59]\n",
    "df6 = df6.transpose()\n",
    "\n",
    "df7 = df[df.absH==7]\n",
    "df7 = df7.set_index('date')\n",
    "del df7['absH']\n",
    "df7 = df7[:59]\n",
    "df7 = df7.transpose()\n",
    "\n",
    "df8 = df[df.absH==8]\n",
    "df8 = df8.set_index('date')\n",
    "del df8['absH']\n",
    "df8 = df8[:59]\n",
    "df8 = df8.transpose()\n",
    "\n",
    "df9 = df[df.absH==9]\n",
    "df9 = df9.set_index('date')\n",
    "del df9['absH']\n",
    "df9 = df9[:59]\n",
    "df9 = df9.transpose()\n",
    "\n",
    "df10 = df[df.absH==10]\n",
    "df10 = df10.set_index('date')\n",
    "del df10['absH']\n",
    "df10 = df10[:59]\n",
    "df10 = df10.transpose()\n",
    "\n",
    "df11 = df[df.absH==11]\n",
    "df11 = df11.set_index('date')\n",
    "del df11['absH']\n",
    "df11 = df11[:59]\n",
    "df11 = df11.transpose()\n",
    "\n",
    "df12 = df[df.absH==12]\n",
    "df12 = df12.set_index('date')\n",
    "del df12['absH']\n",
    "df12 = df12[:59]\n",
    "df12 = df12.transpose()\n",
    "\n",
    "df13 = df[df.absH==13]\n",
    "df13 = df13.set_index('date')\n",
    "del df13['absH']\n",
    "df13 = df13[:59]\n",
    "df13 = df13.transpose()\n",
    "\n",
    "df14 = df[df.absH==14]\n",
    "df14 = df14.set_index('date')\n",
    "del df14['absH']\n",
    "df14 = df14[:59]\n",
    "df14 = df14.transpose()\n",
    "\n",
    "df15 = df[df.absH==15]\n",
    "df15 = df15.set_index('date')\n",
    "del df15['absH']\n",
    "df15 = df15[:59]\n",
    "df15 = df15.transpose()\n",
    "\n",
    "df16 = df[df.absH==16]\n",
    "df16 = df16.set_index('date')\n",
    "del df16['absH']\n",
    "df16 = df16[:59]\n",
    "df16 = df16.transpose()\n",
    "\n",
    "df17 = df[df.absH==17]\n",
    "df17 = df17.set_index('date')\n",
    "del df17['absH']\n",
    "df17 = df17[:59]\n",
    "df17 = df17.transpose()\n",
    "\n",
    "df18 = df[df.absH==18]\n",
    "df18 = df18.set_index('date')\n",
    "del df18['absH']\n",
    "df18 = df18[:59]\n",
    "df18 = df18.transpose()\n",
    "\n",
    "df19 = df[df.absH==19]\n",
    "df19 = df19.set_index('date')\n",
    "del df19['absH']\n",
    "df19 = df19[:59]\n",
    "df19 = df19.transpose()\n",
    "\n",
    "df20 = df[df.absH==20]\n",
    "df20 = df20.set_index('date')\n",
    "del df20['absH']\n",
    "df20 = df20[:59]\n",
    "df20 = df20.transpose()\n",
    "\n",
    "df21 = df[df.absH==21]\n",
    "df21 = df21.set_index('date')\n",
    "del df21['absH']\n",
    "df21 = df21[:59]\n",
    "df21 = df21.transpose()\n",
    "\n",
    "df22 = df[df.absH==22]\n",
    "df22 = df22.set_index('date')\n",
    "del df22['absH']\n",
    "df22 = df22[:59]\n",
    "df22 = df22.transpose()\n",
    "\n",
    "df23 = df[df.absH==23]\n",
    "df23 = df23.set_index('date')\n",
    "del df23['absH']\n",
    "df23 = df23[:59]\n",
    "df23 = df23.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2015-02-09 00:00:00</th>\n",
       "      <th>2015-02-09 00:01:00</th>\n",
       "      <th>2015-02-09 00:02:00</th>\n",
       "      <th>2015-02-09 00:03:00</th>\n",
       "      <th>2015-02-09 00:04:00</th>\n",
       "      <th>2015-02-09 00:04:59</th>\n",
       "      <th>2015-02-09 00:06:00</th>\n",
       "      <th>2015-02-09 00:07:00</th>\n",
       "      <th>2015-02-09 00:08:00</th>\n",
       "      <th>2015-02-09 00:08:59</th>\n",
       "      <th>...</th>\n",
       "      <th>2015-02-09 00:49:00</th>\n",
       "      <th>2015-02-09 00:49:59</th>\n",
       "      <th>2015-02-09 00:51:00</th>\n",
       "      <th>2015-02-09 00:52:00</th>\n",
       "      <th>2015-02-09 00:53:00</th>\n",
       "      <th>2015-02-09 00:53:59</th>\n",
       "      <th>2015-02-09 00:55:00</th>\n",
       "      <th>2015-02-09 00:55:59</th>\n",
       "      <th>2015-02-09 00:56:59</th>\n",
       "      <th>2015-02-09 00:58:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.50</td>\n",
       "      <td>19.5</td>\n",
       "      <td>...</td>\n",
       "      <td>19.39</td>\n",
       "      <td>19.39</td>\n",
       "      <td>19.39</td>\n",
       "      <td>19.390000</td>\n",
       "      <td>19.39</td>\n",
       "      <td>19.39</td>\n",
       "      <td>19.390000</td>\n",
       "      <td>19.39</td>\n",
       "      <td>19.39</td>\n",
       "      <td>19.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity</th>\n",
       "      <td>27.1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>27.05</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.79</td>\n",
       "      <td>26.79</td>\n",
       "      <td>26.79</td>\n",
       "      <td>26.823333</td>\n",
       "      <td>26.79</td>\n",
       "      <td>26.79</td>\n",
       "      <td>26.823333</td>\n",
       "      <td>26.89</td>\n",
       "      <td>26.89</td>\n",
       "      <td>26.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Light</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO2</th>\n",
       "      <td>459.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>456.5</td>\n",
       "      <td>455.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>456.50</td>\n",
       "      <td>456.5</td>\n",
       "      <td>...</td>\n",
       "      <td>462.00</td>\n",
       "      <td>458.00</td>\n",
       "      <td>458.00</td>\n",
       "      <td>459.666667</td>\n",
       "      <td>462.00</td>\n",
       "      <td>462.00</td>\n",
       "      <td>461.333333</td>\n",
       "      <td>461.00</td>\n",
       "      <td>461.00</td>\n",
       "      <td>460.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date         2015-02-09 00:00:00  2015-02-09 00:01:00  2015-02-09 00:02:00  \\\n",
       "Temperature                 19.5                 19.5                 19.5   \n",
       "Humidity                    27.1                 27.1                 27.1   \n",
       "Light                        0.0                  0.0                  0.0   \n",
       "CO2                        459.0                459.0                458.0   \n",
       "\n",
       "date         2015-02-09 00:03:00  2015-02-09 00:04:00  2015-02-09 00:04:59  \\\n",
       "Temperature                 19.5                 19.5                 19.5   \n",
       "Humidity                    27.1                 27.0                 27.0   \n",
       "Light                        0.0                  0.0                  0.0   \n",
       "CO2                        457.0                458.0                456.5   \n",
       "\n",
       "date         2015-02-09 00:06:00  2015-02-09 00:07:00  2015-02-09 00:08:00  \\\n",
       "Temperature                 19.5                 19.5                19.50   \n",
       "Humidity                    27.0                 27.1                27.05   \n",
       "Light                        0.0                  0.0                 0.00   \n",
       "CO2                        455.0                460.0               456.50   \n",
       "\n",
       "date         2015-02-09 00:08:59  ...  2015-02-09 00:49:00  \\\n",
       "Temperature                 19.5  ...                19.39   \n",
       "Humidity                    27.0  ...                26.79   \n",
       "Light                        0.0  ...                 0.00   \n",
       "CO2                        456.5  ...               462.00   \n",
       "\n",
       "date         2015-02-09 00:49:59  2015-02-09 00:51:00  2015-02-09 00:52:00  \\\n",
       "Temperature                19.39                19.39            19.390000   \n",
       "Humidity                   26.79                26.79            26.823333   \n",
       "Light                       0.00                 0.00             0.000000   \n",
       "CO2                       458.00               458.00           459.666667   \n",
       "\n",
       "date         2015-02-09 00:53:00  2015-02-09 00:53:59  2015-02-09 00:55:00  \\\n",
       "Temperature                19.39                19.39            19.390000   \n",
       "Humidity                   26.79                26.79            26.823333   \n",
       "Light                       0.00                 0.00             0.000000   \n",
       "CO2                       462.00               462.00           461.333333   \n",
       "\n",
       "date         2015-02-09 00:55:59  2015-02-09 00:56:59  2015-02-09 00:58:00  \n",
       "Temperature                19.39                19.39                19.39  \n",
       "Humidity                   26.89                26.89                26.89  \n",
       "Light                       0.00                 0.00                 0.00  \n",
       "CO2                       461.00               461.00               460.00  \n",
       "\n",
       "[4 rows x 59 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20.5       ,  20.445     ,  20.445     ,  20.445     ,\n",
       "         20.39      ,  20.39      ,  20.5       ,  20.39      ,\n",
       "         20.39      ,  20.445     ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ,  20.39      ,\n",
       "         20.39      ,  20.39      ,  20.39      ],\n",
       "       [ 33.        ,  33.045     ,  33.        ,  33.        ,\n",
       "         33.        ,  33.        ,  33.        ,  33.        ,\n",
       "         33.        ,  33.0225    ,  33.        ,  33.        ,\n",
       "         33.        ,  33.        ,  33.        ,  33.        ,\n",
       "         33.        ,  32.9       ,  33.        ,  33.        ,\n",
       "         32.9       ,  33.        ,  33.        ,  33.        ,\n",
       "         33.        ,  32.9       ,  33.        ,  33.        ,\n",
       "         33.        ,  33.        ,  33.        ,  32.9       ,\n",
       "         32.9       ,  33.        ,  33.        ,  33.        ,\n",
       "         33.        ,  32.9       ,  32.95      ,  32.95      ,\n",
       "         33.        ,  32.95      ,  32.9       ,  32.9       ,\n",
       "         32.9       ,  32.9       ,  32.9       ,  32.9       ,\n",
       "         32.9       ,  32.9       ,  32.9       ,  32.9       ,\n",
       "         32.9       ,  32.9       ,  32.9       ,  32.9       ,\n",
       "         32.9       ,  32.9       ,  33.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ],\n",
       "       [546.        , 545.5       , 546.        , 543.        ,\n",
       "        544.5       , 545.        , 543.        , 540.5       ,\n",
       "        542.        , 539.5       , 541.        , 540.        ,\n",
       "        538.        , 541.5       , 543.        , 540.5       ,\n",
       "        538.        , 527.        , 526.5       , 530.        ,\n",
       "        527.        , 531.25      , 533.        , 535.33333333,\n",
       "        529.        , 527.        , 531.        , 532.        ,\n",
       "        530.        , 521.        , 521.5       , 524.        ,\n",
       "        523.        , 520.5       , 520.        , 521.33333333,\n",
       "        523.        , 515.        , 514.5       , 511.        ,\n",
       "        513.        , 513.        , 514.        , 511.        ,\n",
       "        502.        , 506.33333333, 505.5       , 510.        ,\n",
       "        508.        , 506.5       , 501.        , 512.        ,\n",
       "        511.        , 504.        , 502.5       , 501.        ,\n",
       "        502.        , 505.        , 506.5       ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.to_numpy()\n",
    "df1.to_numpy()\n",
    "df2.to_numpy()\n",
    "df3.to_numpy()\n",
    "df4.to_numpy()\n",
    "df5.to_numpy()\n",
    "df6.to_numpy()\n",
    "df7.to_numpy()\n",
    "df8.to_numpy()\n",
    "df9.to_numpy()\n",
    "df10.to_numpy()\n",
    "df11.to_numpy()\n",
    "df12.to_numpy()\n",
    "df13.to_numpy()\n",
    "df14.to_numpy()\n",
    "df15.to_numpy()\n",
    "df16.to_numpy()\n",
    "df17.to_numpy()\n",
    "df18.to_numpy()\n",
    "df19.to_numpy()\n",
    "df20.to_numpy()\n",
    "df21.to_numpy()\n",
    "df22.to_numpy()\n",
    "df23.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le raggruppo in un unico dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsMV = np.stack((df0, df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 4, 59)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsMV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 19.5       ,  19.5       ,  19.5       , ...,  19.39      ,\n",
       "          19.39      ,  19.39      ],\n",
       "        [ 27.1       ,  27.1       ,  27.1       , ...,  26.89      ,\n",
       "          26.89      ,  26.89      ],\n",
       "        [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [459.        , 459.        , 458.        , ..., 461.        ,\n",
       "         461.        , 460.        ]],\n",
       "\n",
       "       [[ 19.39      ,  19.39      ,  19.5       , ...,  19.39      ,\n",
       "          19.39      ,  19.39      ],\n",
       "        [ 26.89      ,  27.        ,  27.        , ...,  27.16666667,\n",
       "          27.1       ,  27.1       ],\n",
       "        [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [462.5       , 462.5       , 463.        , ..., 468.        ,\n",
       "         468.5       , 466.        ]],\n",
       "\n",
       "       [[ 19.39      ,  19.39      ,  19.39      , ...,  19.5       ,\n",
       "          19.42666667,  19.39      ],\n",
       "        [ 27.1       ,  27.1       ,  27.1       , ...,  26.7       ,\n",
       "          26.63333333,  26.66666667],\n",
       "        [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [466.5       , 467.5       , 465.        , ..., 473.        ,\n",
       "         475.66666667, 470.66666667]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 20.5       ,  20.5       ,  20.5       , ...,  20.5       ,\n",
       "          20.5       ,  20.5       ],\n",
       "        [ 34.0675    ,  34.09      ,  34.045     , ...,  33.5       ,\n",
       "          33.5       ,  33.45      ],\n",
       "        [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [762.5       , 756.        , 748.5       , ..., 634.        ,\n",
       "         632.        , 637.5       ]],\n",
       "\n",
       "       [[ 20.5       ,  20.5       ,  20.5       , ...,  20.42666667,\n",
       "          20.5       ,  20.5       ],\n",
       "        [ 33.4       ,  33.4       ,  33.4       , ...,  33.03      ,\n",
       "          33.09      ,  33.09      ],\n",
       "        [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [646.5       , 629.        , 622.        , ..., 549.        ,\n",
       "         554.        , 550.        ]],\n",
       "\n",
       "       [[ 20.5       ,  20.445     ,  20.445     , ...,  20.39      ,\n",
       "          20.39      ,  20.39      ],\n",
       "        [ 33.        ,  33.045     ,  33.        , ...,  32.9       ,\n",
       "          32.9       ,  33.        ],\n",
       "        [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [546.        , 545.5       , 546.        , ..., 502.        ,\n",
       "         505.        , 506.5       ]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsMV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label scelti assegnati manualmente in riferimento all'orario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['notte','notte','notte','notte','notte','notte','mattina','mattina','mattina','mattina','mattina','mattina','mattina','mattina','pomeriggio','pomeriggio','pomeriggio','pomeriggio','pomeriggio','pomeriggio','pomeriggio','pomeriggio','notte','notte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dsMV, label, test_size=0.3, random_state=100, stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4, 59)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4, 59)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.datasets import load_basic_motions\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  21.5       ,   21.5       ,   21.5       , ...,\n",
       "           21.29      ,   21.29      ,   21.29      ],\n",
       "        [  33.5       ,   33.46666667,   33.425     , ...,\n",
       "           32.975     ,   32.95      ,   32.95      ],\n",
       "        [ 475.25      ,  464.        ,  464.        , ...,\n",
       "          469.25      ,  474.5       ,  474.5       ],\n",
       "        [1281.5       , 1283.33333333, 1279.25      , ...,\n",
       "         1130.5       , 1131.5       , 1129.5       ]],\n",
       "\n",
       "       [[  21.29      ,   21.29      ,   21.29      , ...,\n",
       "           21.89      ,   21.89      ,   21.89      ],\n",
       "        [  33.05      ,   33.2225    ,   33.045     , ...,\n",
       "           36.32666667,   36.425     ,   36.53      ],\n",
       "        [ 451.5       ,  459.        ,  459.        , ...,\n",
       "          464.        ,  457.75      ,  454.        ],\n",
       "        [1129.        , 1147.25      , 1143.5       , ...,\n",
       "         1580.        , 1581.        , 1592.66666667]],\n",
       "\n",
       "       [[  20.5       ,   20.445     ,   20.445     , ...,\n",
       "           20.39      ,   20.39      ,   20.39      ],\n",
       "        [  33.        ,   33.045     ,   33.        , ...,\n",
       "           32.9       ,   32.9       ,   33.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [ 546.        ,  545.5       ,  546.        , ...,\n",
       "          502.        ,  505.        ,  506.5       ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  20.6       ,   20.6       ,   20.6       , ...,\n",
       "           20.5       ,   20.5       ,   20.5       ],\n",
       "        [  35.09      ,   35.09      ,   35.09      , ...,\n",
       "           34.09      ,   34.09      ,   34.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [1001.        , 1000.        , 1001.        , ...,\n",
       "          774.        ,  767.        ,  771.        ]],\n",
       "\n",
       "       [[  19.34      ,   19.29      ,   19.29      , ...,\n",
       "           19.5       ,   19.445     ,   19.445     ],\n",
       "        [  26.1       ,   26.1       ,   26.1       , ...,\n",
       "           26.5       ,   26.5       ,   26.5       ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [ 470.5       ,  471.        ,  470.        , ...,\n",
       "          472.        ,  468.5       ,  470.5       ]],\n",
       "\n",
       "       [[  19.34      ,   19.39      ,   19.34      , ...,\n",
       "           19.29      ,   19.29      ,   19.29      ],\n",
       "        [  26.7       ,   26.7       ,   26.7       , ...,\n",
       "           26.89      ,   26.89      ,   26.89      ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [ 465.        ,  467.        ,  471.5       , ...,\n",
       "          465.33333333,  465.        ,  466.        ]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizzazione????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = TimeSeriesScalerMinMax()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trasformo i label in valori da 0 a 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(16, 59, 4)\n",
    "X_test = X_test.reshape(8, 59, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  59\n",
      "N. LABELS:  3\n",
      "N. FEATURES:  4\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_outputs, n_features = X_train.shape[1], len(np.unique(y_train)), X_train.shape[2] \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)\n",
    "print(\"N. FEATURES: \", n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPool2D, Flatten, Dropout, LeakyReLU, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm2(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(n_timesteps, n_features), return_sequences=True, \n",
    "                        kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #1\n",
    "    for _ in range(2):\n",
    "        model.add(LSTM(4, kernel_initializer='TruncatedNormal', return_sequences=True))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.04))   \n",
    "\n",
    "    #2\n",
    "    model.add(LSTM(32, kernel_initializer='TruncatedNormal', return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.7))\n",
    "    \n",
    "    #3\n",
    "    for _ in range(2):\n",
    "        model.add(Dense(256, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.2))\n",
    "    #4\n",
    "    for _ in range(1):\n",
    "        model.add(Dense(64, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.7))\n",
    "\n",
    "    #5\n",
    "    model.add(Dense(32, kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "        \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\gdm17\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "lstm2 = build_lstm2(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 59, 4)             144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 59, 4)             16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 59, 4)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 59, 4)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 59, 4)             144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 59, 4)             16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 59, 4)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 59, 4)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 59, 4)             144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 59, 4)             16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 59, 4)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 59, 4)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 100,643\n",
      "Trainable params: 99,339\n",
      "Non-trainable params: 1,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_lstm2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\gdm17\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\gdm17\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 12 samples, validate on 4 samples\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 1.1000 - accuracy: 0.3333 - val_loss: 1.0981 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 1.0992 - accuracy: 0.0000e+00 - val_loss: 1.0977 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 1.0990 - accuracy: 0.3333 - val_loss: 1.0982 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 1.0988 - accuracy: 0.3333 - val_loss: 1.0981 - val_accuracy: 0.2500\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 1.0990 - accuracy: 0.3333 - val_loss: 1.0981 - val_accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 1.0986 - accuracy: 0.5000 - val_loss: 1.0978 - val_accuracy: 0.2500\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 1.0993 - accuracy: 0.2500 - val_loss: 1.0975 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 1.0983 - accuracy: 0.4167 - val_loss: 1.0973 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 1.0999 - accuracy: 0.2500 - val_loss: 1.0962 - val_accuracy: 0.2500\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 1.0988 - accuracy: 0.4167 - val_loss: 1.0957 - val_accuracy: 0.2500\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 1.0945 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 1.1001 - accuracy: 0.3333 - val_loss: 1.0930 - val_accuracy: 0.2500\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 1.0987 - accuracy: 0.3333 - val_loss: 1.0899 - val_accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 1.0991 - accuracy: 0.4167 - val_loss: 1.0869 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 1.0979 - accuracy: 0.3333 - val_loss: 1.0836 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0789 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0762 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 1.0992 - accuracy: 0.4167 - val_loss: 1.0751 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 1.0976 - accuracy: 0.5000 - val_loss: 1.0819 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 1.0991 - accuracy: 0.2500 - val_loss: 1.1077 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 1.0986 - accuracy: 0.2500 - val_loss: 1.1689 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 1.0996 - accuracy: 0.3333 - val_loss: 1.2904 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 1.1014 - accuracy: 0.2500 - val_loss: 1.4843 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 1.0980 - accuracy: 0.2500 - val_loss: 1.7830 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 1.0991 - accuracy: 0.4167 - val_loss: 2.2073 - val_accuracy: 0.5000\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 2.7670 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 1.1006 - accuracy: 0.1667 - val_loss: 3.5074 - val_accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 1.1001 - accuracy: 0.2500 - val_loss: 4.5314 - val_accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 1.0976 - accuracy: 0.4167 - val_loss: 4.7182 - val_accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 1.0980 - accuracy: 0.3333 - val_loss: 4.7217 - val_accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 1.0979 - accuracy: 0.4167 - val_loss: 4.7225 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 1.1009 - accuracy: 0.2500 - val_loss: 4.7226 - val_accuracy: 0.5000\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 1.1000 - accuracy: 0.2500 - val_loss: 4.7227 - val_accuracy: 0.5000\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 1.1006 - accuracy: 0.1667 - val_loss: 4.7227 - val_accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 1.1002 - accuracy: 0.2500 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 1.1002 - accuracy: 0.3333 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 1.0987 - accuracy: 0.1667 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 1.0987 - accuracy: 0.2500 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 1.1003 - accuracy: 0.3333 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 1.1004 - accuracy: 0.0833 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 1.0985 - accuracy: 0.2500 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 1.0981 - accuracy: 0.5000 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 1.1001 - accuracy: 0.3333 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 1.1003 - accuracy: 0.2500 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 1.0964 - accuracy: 0.3333 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 1.0975 - accuracy: 0.3333 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 1.1010 - accuracy: 0.2500 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 1.1000 - accuracy: 0.2500 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 1.1009 - accuracy: 0.1667 - val_loss: 4.7227 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "history_lstm2 = lstm2.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                          validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.375\n",
      "F1-score [0.54545455 0.         0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gdm17\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(lstm2.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 59, 4, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cnn2 = X_train_cnn.reshape(X_train_cnn.shape[0], X_train_cnn.shape[1], X_train_cnn.shape[2], 1)\n",
    "X_val_cnn2 = X_val_cnn.reshape(X_val_cnn.shape[0], X_val_cnn.shape[1], X_val_cnn.shape[2], 1)\n",
    "X_test_cnn2 = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "X_train_cnn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn2(n_timesteps, n_features, n_outputs):\n",
    "    input_shape = (n_timesteps, n_features, 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    ks1_first = 3\n",
    "    ks1_second = 3\n",
    "    \n",
    "    ks2_first = 4\n",
    "    ks2_second = 4\n",
    "    \n",
    "    model.add(Conv2D(filters=(3), \n",
    "                     kernel_size=(ks1_first, ks1_second),\n",
    "                     input_shape=input_shape, \n",
    "                     padding='same',\n",
    "                     kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.02))\n",
    "    \n",
    "    for _ in range(2):\n",
    "        model.add(Conv2D(filters=(4), \n",
    "                     kernel_size= (ks2_first, ks2_second), \n",
    "                         padding='same',\n",
    "                     kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.2))  \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for _ in range(4):\n",
    "        model.add(Dense(64 , kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.4))\n",
    "    \n",
    "    for _ in range(3):\n",
    "        model.add(Dense(128 , kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(1024 , kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.7))\n",
    "        \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "cnn2 = build_cnn2(n_timesteps, n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 59, 4, 3)          30        \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 59, 4, 3)          12        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 59, 4, 3)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 59, 4, 3)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 59, 4, 4)          196       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 59, 4, 4)          16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 59, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 59, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 59, 4, 4)          260       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 59, 4, 4)          16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 59, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 59, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 944)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                60480     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 256,661\n",
      "Trainable params: 253,311\n",
      "Non-trainable params: 3,350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples, validate on 4 samples\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 1.0996 - accuracy: 0.3333 - val_loss: 1.0996 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1005 - accuracy: 0.3333 - val_loss: 1.0999 - val_accuracy: 0.2500\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0958 - accuracy: 0.4167 - val_loss: 1.0997 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1001 - accuracy: 0.5000 - val_loss: 1.1025 - val_accuracy: 0.2500\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1016 - accuracy: 0.0833 - val_loss: 1.1032 - val_accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0981 - accuracy: 0.3333 - val_loss: 1.1007 - val_accuracy: 0.2500\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0994 - accuracy: 0.2500 - val_loss: 1.0998 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1013 - accuracy: 0.1667 - val_loss: 1.0987 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1050 - accuracy: 0.1667 - val_loss: 1.1007 - val_accuracy: 0.2500\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1048 - accuracy: 0.0833 - val_loss: 1.1006 - val_accuracy: 0.2500\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0993 - accuracy: 0.3333 - val_loss: 1.0981 - val_accuracy: 0.2500\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0989 - accuracy: 0.2500 - val_loss: 1.0999 - val_accuracy: 0.2500\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0998 - accuracy: 0.3333 - val_loss: 1.1007 - val_accuracy: 0.2500\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0985 - accuracy: 0.2500 - val_loss: 1.1040 - val_accuracy: 0.2500\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1028 - accuracy: 0.2500 - val_loss: 1.1098 - val_accuracy: 0.2500\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0991 - accuracy: 0.3333 - val_loss: 1.1283 - val_accuracy: 0.2500\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0970 - accuracy: 0.5000 - val_loss: 1.1709 - val_accuracy: 0.2500\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1005 - accuracy: 0.1667 - val_loss: 1.2883 - val_accuracy: 0.2500\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1006 - accuracy: 0.2500 - val_loss: 1.5074 - val_accuracy: 0.2500\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1031 - accuracy: 0.1667 - val_loss: 1.9175 - val_accuracy: 0.2500\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0982 - accuracy: 0.3333 - val_loss: 2.6930 - val_accuracy: 0.2500\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.1022 - accuracy: 0.0833 - val_loss: 3.8688 - val_accuracy: 0.2500\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0937 - accuracy: 0.3333 - val_loss: 4.7722 - val_accuracy: 0.2500\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0965 - accuracy: 0.3333 - val_loss: 4.8191 - val_accuracy: 0.2500\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0979 - accuracy: 0.3333 - val_loss: 5.0591 - val_accuracy: 0.2500\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0965 - accuracy: 0.2500 - val_loss: 6.7727 - val_accuracy: 0.2500\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1000 - accuracy: 0.3333 - val_loss: 5.4404 - val_accuracy: 0.2500\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0967 - accuracy: 0.5000 - val_loss: 6.5757 - val_accuracy: 0.2500\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1088 - accuracy: 0.2500 - val_loss: 5.0149 - val_accuracy: 0.2500\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1007 - accuracy: 0.3333 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1090 - accuracy: 0.0833 - val_loss: 5.0508 - val_accuracy: 0.2500\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0939 - accuracy: 0.4167 - val_loss: 12.2518 - val_accuracy: 0.2500\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0985 - accuracy: 0.2500 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1046 - accuracy: 0.3333 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0850 - accuracy: 0.6667 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0890 - accuracy: 0.5000 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0908 - accuracy: 0.4167 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0923 - accuracy: 0.4167 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0984 - accuracy: 0.5000 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0945 - accuracy: 0.2500 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1006 - accuracy: 0.2500 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1109 - accuracy: 0.1667 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0853 - accuracy: 0.5000 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1039 - accuracy: 0.1667 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1084 - accuracy: 0.3333 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0907 - accuracy: 0.4167 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1028 - accuracy: 0.1667 - val_loss: 4.7227 - val_accuracy: 0.2500\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1070 - accuracy: 0.1667 - val_loss: 12.4351 - val_accuracy: 0.2500\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 12.4351 - val_accuracy: 0.2500\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0902 - accuracy: 0.5000 - val_loss: 12.2619 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "history_cnn2 = cnn2.fit(X_train_cnn2, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn2, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.375\n",
      "F1-score [0.54545455 0.         0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gdm17\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(cnn2.predict(X_test_cnn2), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn3(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = build_cnn3(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 52, 16)            528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 52, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 52, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 48, 32)            2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 48, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 46, 64)            6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 46, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 46, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 46, 64)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 9,971\n",
      "Trainable params: 9,747\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.25\n",
      "F1-score [0.  0.4 0. ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.25      1.00      0.40         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.08      0.33      0.13         8\n",
      "weighted avg       0.06      0.25      0.10         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(cnn3.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapelet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\gdm17\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adagrad\n",
    "from tslearn.shapelets import ShapeletModel\n",
    "from tslearn.shapelets import grabocka_params_to_shapelet_size_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ts, ts_sz = X_train.shape[0],X_train.shape[1]\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ts 16\n",
      "ts_sz 4\n",
      "n_classes 3\n",
      "shapelet_sizes {2: 1}\n"
     ]
    }
   ],
   "source": [
    "shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=n_ts,\n",
    "                                                       ts_sz=ts_sz,\n",
    "                                                       n_classes=n_classes,\n",
    "                                                       l=0.5,\n",
    "                                                       r=1)\n",
    "\n",
    "print('n_ts', n_ts)\n",
    "print('ts_sz', ts_sz)\n",
    "print('n_classes', n_classes)\n",
    "print('shapelet_sizes', shapelet_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_clf = ShapeletModel(n_shapelets_per_size=shapelet_sizes,\n",
    "                        optimizer=\"sgd\",\n",
    "                        weight_regularizer=.01,\n",
    "                        max_iter=200,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 122ms/step - loss: 1.8360 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.8322\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 424us/step - loss: 1.7930 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.7894\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 374us/step - loss: 1.7523 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.7489\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.7137 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.7106\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.6773 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.6743\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.6429 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.6401\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.6104 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.6077\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 624us/step - loss: 1.5797 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.5772\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.5507 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.5483\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.5233 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.5211\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.4975 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.4954\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.4731 - categorical_accuracy: 0.3125 - categorical_crossentropy: 1.4712\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.4502 - categorical_accuracy: 0.2500 - categorical_crossentropy: 1.4483\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 471us/step - loss: 1.4285 - categorical_accuracy: 0.2500 - categorical_crossentropy: 1.4267\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1.4081 - categorical_accuracy: 0.2500 - categorical_crossentropy: 1.4064\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.3888 - categorical_accuracy: 0.2500 - categorical_crossentropy: 1.3872\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.3706 - categorical_accuracy: 0.1875 - categorical_crossentropy: 1.3691\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 373us/step - loss: 1.3534 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.3521\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.3373 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.3359\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 684us/step - loss: 1.3220 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.3208\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 621us/step - loss: 1.3076 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.3064\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 435us/step - loss: 1.2940 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.2929\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.2811 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.2801\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 624us/step - loss: 1.2690 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.2680\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.2575 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.2566\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.2467 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.2458\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.2365 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.2356\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.2268 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.2260\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1.2176 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.2169\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.2090 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.2082\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.2008 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.2001\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1930 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1923\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1856 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1850\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.1787 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1781\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.1721 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1715\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.1658 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1652\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1598 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1593\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1542 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1537\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 748us/step - loss: 1.1488 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1483\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.1437 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1433\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.1389 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1384\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1343 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1338\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.1299 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1295\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1257 - categorical_accuracy: 0.1250 - categorical_crossentropy: 1.1253\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1218 - categorical_accuracy: 0.0625 - categorical_crossentropy: 1.1214\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1180 - categorical_accuracy: 0.0625 - categorical_crossentropy: 1.1176\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 498us/step - loss: 1.1144 - categorical_accuracy: 0.0625 - categorical_crossentropy: 1.1140\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1109 - categorical_accuracy: 0.0625 - categorical_crossentropy: 1.1106\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1077 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.1073\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.1045 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.1042\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.1015 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.1012\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0987 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0983\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0960 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0956\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 498us/step - loss: 1.0933 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0930\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0909 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0905\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 437us/step - loss: 1.0885 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0862 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0858\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0840 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0837\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0819 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0816\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0799 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0796\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0780 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0776\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0761 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0758\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0743 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0740\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0726 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0723\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0710 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0707\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0694 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0691\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0679 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0676\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0664 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0661\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0650 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0647\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0637 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0633\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0624 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0620\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0611 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0608\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0599 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0595\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0587 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0584\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0576 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0572\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0565 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0561\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0554 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0551\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0544 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0540\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0534 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0530\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0524 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0521\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 374us/step - loss: 1.0515 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0511\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0506 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0502\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0497 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0494\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0489 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0485\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0481 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0477\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0473 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0469\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0465 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0461\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0457 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0453\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0450 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0446\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0443 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0439\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0436 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0432\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0429 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0425\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0423 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0419\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0416 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0412\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0410 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0406\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0404 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0400\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0398 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0394\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0392 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0388\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0386 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0382\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0381 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0376\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0375 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0371\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0370 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0366\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0365 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0360\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0360 - categorical_accuracy: 0.3750 - categorical_crossentropy: 1.0355\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0355 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0350\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0350 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0345\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0345 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0340\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0340 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0336\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0336 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0331\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0331 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0326\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0327 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0322 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0317\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0318 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0313\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0314 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0309\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0310 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0305\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0306 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0301\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0302 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0297\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0298 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0293\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0294 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0289\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0290 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0285\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0286 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0281\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0283 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0277\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0279 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0273\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0275 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0270\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0272 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0266\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0268 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0263\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0265 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0259\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1.0261 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0256\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0258 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0252\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0254 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0249\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0251 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0245\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0248 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0242\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0245 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0239\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0241 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0236\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0238 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0232\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0235 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0229\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0232 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0226\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 501us/step - loss: 1.0229 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0223\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0226 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0220\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 501us/step - loss: 1.0223 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0217\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0220 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0214\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 438us/step - loss: 1.0217 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0211\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0214 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0208\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0211 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0205\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 497us/step - loss: 1.0208 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0202\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0205 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0199\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 498us/step - loss: 1.0203 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0196\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0200 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0193\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 438us/step - loss: 1.0197 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0190\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 559us/step - loss: 1.0194 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0188\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0191 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0185\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 434us/step - loss: 1.0189 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0182\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0186 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0179\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0183 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0177\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0181 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0174\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0178 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0171\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0175 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0169\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 497us/step - loss: 1.0173 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0166\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0170 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0163\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 496us/step - loss: 1.0168 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0161\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0165 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0158\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0163 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0155\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0160 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0153\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 497us/step - loss: 1.0157 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0150\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0155 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0148\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 496us/step - loss: 1.0152 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0150 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0143\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0148 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0140\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 438us/step - loss: 1.0145 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0138\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0143 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0135\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 686us/step - loss: 1.0140 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0133\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 501us/step - loss: 1.0138 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0130\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0135 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0128\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 497us/step - loss: 1.0133 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0126\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0131 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0123\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0128 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0121\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 497us/step - loss: 1.0126 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0118\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0124 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0116\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0121 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0114\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 561us/step - loss: 1.0119 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0111\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0117 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0109\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0114 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0107\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0112 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0104\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0110 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0102\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0107 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0100\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 497us/step - loss: 1.0105 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0097\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 438us/step - loss: 1.0103 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0095\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0101 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0093\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0098 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0090\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0096 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0088\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0094 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0086\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 497us/step - loss: 1.0092 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0084\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0090 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0081\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 501us/step - loss: 1.0087 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0079\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0085 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0077\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 498us/step - loss: 1.0083 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0075\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0081 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0072\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 497us/step - loss: 1.0079 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0070\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 436us/step - loss: 1.0076 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0068\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.0074 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.0066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeletModel(max_iter=200, n_shapelets_per_size={2: 1}, verbose=1,\n",
       "              weight_regularizer=0.01)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "8/8 [==============================] - 1s 116ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = shp_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.25\n",
      "F1-score [0.  0.4 0. ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.25      1.00      0.40         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.08      0.33      0.13         8\n",
      "weighted avg       0.06      0.25      0.10         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gdm17\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
